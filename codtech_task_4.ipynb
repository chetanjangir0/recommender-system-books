{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.23.5 -q\n",
        "!pip uninstall scikit-surprise -y -q\n",
        "!pip install scikit-surprise -q\n",
        "\n",
        "import pandas as pd\n",
        "from surprise import SVD, Dataset, Reader, BaselineOnly\n",
        "from surprise.model_selection import train_test_split as surprise_train_test_split\n",
        "from surprise.model_selection import GridSearchCV\n",
        "from surprise import accuracy\n",
        "from collections import defaultdict\n",
        "import numpy as np # Ensure numpy is imported"
      ],
      "metadata": {
        "id": "6i74DBVmdHPi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loading the dataset\n",
        "you can get the latest data from [keggle](https://www.kaggle.com/datasets/zygmunt/goodbooks-10k?select=books.csv)"
      ],
      "metadata": {
        "id": "X3shyZWcbPxq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH21riGBXO8z",
        "outputId": "23a989e4-b3d5-4fb0-cf2b-0e6fcec72a3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# Load the datasets\n",
        "try:\n",
        "    ratings = pd.read_csv('ratings.csv')\n",
        "    books   = pd.read_csv('books.csv')\n",
        "    print(\"Datasets loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'ratings.csv' or 'books.csv' not found. Please upload them.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge ratings with book titles for easier interpretation later\n",
        "data = pd.merge(ratings, books[['book_id', 'title']], on='book_id', how='left')\n",
        "# print(\"Merged Data Head:\")\n",
        "# print(data.head())"
      ],
      "metadata": {
        "id": "PyFO5ha8XpiH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic statstic and filtering"
      ],
      "metadata": {
        "id": "EpmEvsZdcCsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Initial Stats:\")\n",
        "print(f\"Total ratings: {data.shape[0]}\")\n",
        "print(f\"Unique users: {data['user_id'].nunique()}\")\n",
        "print(f\"Unique books: {data['book_id'].nunique()}\")\n",
        "\n",
        "# Filtering thresholds\n",
        "min_user_ratings = 10\n",
        "min_book_ratings = 5\n",
        "\n",
        "# Filter users\n",
        "user_counts = data['user_id'].value_counts()\n",
        "data = data[data['user_id'].isin(user_counts[user_counts >= min_user_ratings].index)]\n",
        "\n",
        "# Filter books\n",
        "book_counts = data['book_id'].value_counts()\n",
        "data = data[data['book_id'].isin(book_counts[book_counts >= min_book_ratings].index)]\n",
        "\n",
        "print(\"\\nStats After Filtering:\")\n",
        "print(f\"Total ratings: {data.shape[0]}\")\n",
        "print(f\"Unique users: {data['user_id'].nunique()}\")\n",
        "print(f\"Unique books: {data['book_id'].nunique()}\")"
      ],
      "metadata": {
        "id": "BGW7xepfX_ln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f171b0-5bf5-45f8-c152-09d90a27a33d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Stats:\n",
            "Total ratings: 981756\n",
            "Unique users: 53424\n",
            "Unique books: 10000\n",
            "\n",
            "Stats After Filtering:\n",
            "Total ratings: 857533\n",
            "Unique users: 24405\n",
            "Unique books: 9998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering users and books with less than a set threshold of interactions\n",
        "min_user_ratings = 10\n",
        "min_book_ratings = 5\n",
        "\n",
        "user_counts = data['user_id'].value_counts()\n",
        "book_counts = data['book_id'].value_counts()\n",
        "\n",
        "data = data[data['user_id'].isin(user_counts[user_counts >= min_user_ratings].index)]\n",
        "data = data[data['book_id'].isin(book_counts[book_counts >= min_book_ratings].index)]"
      ],
      "metadata": {
        "id": "uvRvwI7JcEjv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## preparing data for surprise"
      ],
      "metadata": {
        "id": "N8mCVKGkcXra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "surprise_data = Dataset.load_from_df(data[['user_id', 'book_id', 'rating']], reader)\n",
        "print(\"Data prepared for Surprise library.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqJRcHTecON3",
        "outputId": "b9288a08-472c-4cbc-9e6a-9d86ae41a1f0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data prepared for Surprise library.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting"
      ],
      "metadata": {
        "id": "rgA-2lZMmezK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, testset = surprise_train_test_split(surprise_data, test_size=0.2, random_state=42)\n",
        "print(f\"Trainset size: {trainset.n_ratings}\")\n",
        "print(f\"Testset size: {len(testset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpSHpzInmg8E",
        "outputId": "7f762673-fee1-40c9-e75e-31994136d8cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainset size: 686026\n",
            "Testset size: 171507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyperparameter tuning using grid search"
      ],
      "metadata": {
        "id": "BiGLvKhumuov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_svd = {\n",
        "    'n_factors': [50, 100],\n",
        "    'n_epochs': [20, 30],\n",
        "    'lr_all': [0.005, 0.01],\n",
        "    'reg_all': [0.02, 0.1]\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV\n",
        "gs_svd = GridSearchCV(SVD, param_grid_svd, measures=['rmse', 'mae'], cv=3, n_jobs=-1, joblib_verbose=2)"
      ],
      "metadata": {
        "id": "cwgHwJExmyZD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs_svd.fit(surprise_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKzfYzrynAWd",
        "outputId": "2f5930d3-c315-4ed8-9aaf-1c2dd2131bc4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  6.7min finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print the best score and parameters"
      ],
      "metadata": {
        "id": "R6S_P-RjnGMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nBest SVD RMSE score (on CV): {gs_svd.best_score['rmse']:.4f}\")\n",
        "print(f\"Best SVD MAE score (on CV): {gs_svd.best_score['mae']:.4f}\")\n",
        "print(\"Best SVD parameters found:\", gs_svd.best_params['rmse'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSg7OmXxnHez",
        "outputId": "ebb167da-70bc-4531-ea9c-419c3fd2bf4e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best SVD RMSE score (on CV): 0.8250\n",
            "Best SVD MAE score (on CV): 0.6426\n",
            "Best SVD parameters found: {'n_factors': 100, 'n_epochs': 30, 'lr_all': 0.01, 'reg_all': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best SVD estimator model found by GridSearchCV\n",
        "best_svd_model = gs_svd.best_estimator['rmse']"
      ],
      "metadata": {
        "id": "bLcyJ-fWnayH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train and evaluate the best svd model"
      ],
      "metadata": {
        "id": "qlfFaMd9nibg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the best SVD model\n",
        "best_svd_model.fit(trainset)\n",
        "\n",
        "# Evaluate the best SVD model\n",
        "svd_predictions = best_svd_model.test(testset)\n",
        "\n",
        "svd_rmse = accuracy.rmse(svd_predictions)\n",
        "svd_mae = accuracy.mae(svd_predictions)\n",
        "print(f\"Best SVD Test RMSE: {svd_rmse:.4f}\")\n",
        "print(f\"Best SVD Test MAE: {svd_mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQz_U1PynlX5",
        "outputId": "57179c0a-d9b2-49dd-e041-585982b39f18"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.8181\n",
            "MAE:  0.6358\n",
            "Best SVD Test RMSE: 0.8181\n",
            "Best SVD Test MAE: 0.6358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train and evaluate baseline model"
      ],
      "metadata": {
        "id": "tcKkwopXnzeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bsl_options = {'method': 'als', 'n_epochs': 10} # Using ALS optimization\n",
        "\n",
        "baseline_model = BaselineOnly(bsl_options=bsl_options)\n",
        "baseline_model.fit(trainset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOIhclM5n18E",
        "outputId": "f3e29a7c-f644-4a92-d2bc-6b07516a2ac9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.baseline_only.BaselineOnly at 0x7e8a6e449190>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_predictions = baseline_model.test(testset)\n",
        "\n",
        "baseline_rmse = accuracy.rmse(baseline_predictions)\n",
        "baseline_mae = accuracy.mae(baseline_predictions)\n",
        "print(f\"Baseline Test RMSE: {baseline_rmse:.4f}\")\n",
        "print(f\"Baseline Test MAE: {baseline_mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7MG2Ku0n-W9",
        "outputId": "9ad78f6d-48b7-4a4b-85ce-67e5b937562c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.8377\n",
            "MAE:  0.6615\n",
            "Baseline Test RMSE: 0.8377\n",
            "Baseline Test MAE: 0.6615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
        "    user_est_true = defaultdict(list)\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        user_est_true[uid].append((est, true_r))\n",
        "\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
        "                              for (est, true_r) in user_ratings[:k])\n",
        "\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1.0\n",
        "\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1.0\n",
        "\n",
        "    # Average precision and recall over all users\n",
        "    average_precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
        "    average_recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
        "\n",
        "    return average_precision, average_recall"
      ],
      "metadata": {
        "id": "U_WAliqKoC4e"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ranking matrices for best svd model"
      ],
      "metadata": {
        "id": "uG8DuI3joXZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_value = 10\n",
        "relevance_threshold = 3.5\n",
        "\n",
        "print(f\"\\nCalculating Precision and Recall @ k={k_value} for Best SVD Model (threshold={relevance_threshold})...\")\n",
        "svd_avg_precision, svd_avg_recall = precision_recall_at_k(svd_predictions, k=k_value, threshold=relevance_threshold)\n",
        "\n",
        "print(f\"Average Precision@{k_value}: {svd_avg_precision:.4f}\")\n",
        "print(f\"Average Recall@{k_value}: {svd_avg_recall:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhA2Oq9noclm",
        "outputId": "87708d56-3643-4248-d14e-705f1ed06373"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calculating Precision and Recall @ k=10 for Best SVD Model (threshold=3.5)...\n",
            "Average Precision@10: 0.7679\n",
            "Average Recall@10: 0.7928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## top n recommendations"
      ],
      "metadata": {
        "id": "VVYERU5Kooke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_n(predictions, n=10):\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True) # Sort by estimated rating\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n"
      ],
      "metadata": {
        "id": "cxOEm7mdop5u"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}